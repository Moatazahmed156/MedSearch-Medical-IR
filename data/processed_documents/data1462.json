{
    "title": "PLDP-FL: Federated Learning with Personalized Local Differential Privacy.",
    "doc_id": "36981374",
    "writer": "Shen X",
    "year": "2023",
    "summary": "",
    "abstract": "As a popular machine learning method, federated learning (FL) can effectively solve the issues of data silos and data privacy. However, traditional federated learning schemes cannot provide sufficient privacy protection. Furthermore, most secure federated learning schemes based on local differential privacy (LDP) ignore an important issue: they do not consider each client's differentiated privacy requirements. This paper introduces a perturbation algorithm (PDPM) that satisfies personalized local differential privacy (PLDP), resolving the issue of inadequate or excessive privacy protection for some participants due to the same privacy budget set for all clients. The algorithm enables clients to adjust the privacy parameters according to the sensitivity of their data, thus allowing the scheme to provide personalized privacy protection. To ensure the privacy of the scheme, we have conducted a strict privacy proof and simulated the scheme on both synthetic and real data sets. Experiments have demonstrated that our scheme is successful in producing high-quality models and fulfilling the demands of personalized privacy protection.",
    "link": "https://pubmed.ncbi.nlm.nih.gov/36981374/",
    "clean_text": "pldp fl federated learning with personalized local differential privacy as a popular machine learning method federated learning fl can effectively solve the issues of data silos and data privacy however traditional federated learning schemes cannot provide sufficient privacy protection furthermore most secure federated learning schemes based on local differential privacy ldp ignore an important issue they do not consider each client s differentiated privacy requirements this paper introduces a perturbation algorithm pdpm that satisfies personalized local differential privacy pldp resolving the issue of inadequate or excessive privacy protection for some participants due to the same privacy budget set for all clients the algorithm enables clients to adjust the privacy parameters according to the sensitivity of their data thus allowing the scheme to provide personalized privacy protection to ensure the privacy of the scheme we have conducted a strict privacy proof and simulated the scheme on both synthetic and real data sets experiments have demonstrated that our scheme is successful in producing high quality models and fulfilling the demands of personalized privacy protection"
}