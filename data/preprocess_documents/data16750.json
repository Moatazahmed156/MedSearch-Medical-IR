{
    "pmid": "41445654",
    "title": "Is it possible to vaccinate AI against bias? An exploratory study in epilepsy.",
    "abstract": "Large language models are increasingly used for clinical decision support yet may perpetuate socioeconomic biases. Whether simple prompt-based interventions can mitigate such biases remains unknown. To determine whether a prompt-based 'inoculation' instructing large-language-models (LLMs) to disregard clinically irrelevant information can reduce bias and improve accuracy in recommendations. Experimental study conducted November 21 to December 11, 2025. Each clinical vignette was presented 10 times per condition to account for stochastic variance. Publicly available web interfaces of six frontier LLMs with memory features disabled. No real patients were involved. Two fictional epilepsy vignettes (diagnostic and therapeutic) were created with identical clinical features but differing socioeconomic (SES) descriptors. Accuracy (proportion of responses concordant with guidelines) and bias (accuracy difference between high and low SES vignettes), assessed via binary scoring based on evidence-based guidelines. A total of 480 LLM responses were analyzed. For diagnosis, base accuracy was 36% (43/120), with 45 percentage point bias gap (high SES 58% vs. low SES 13%); inoculation improved accuracy to 55% (66/120) and reduced bias to 27 percentage points. For treatment, base accuracy was 51% (61/120) with 25 percentage point bias gap; inoculation improved accuracy to 63% (75/120) and reduced bias to 8 percentage points. Responses to inoculation varied considerably: Gemini 3 Pro showed complete diagnostic bias elimination (low SES accuracy 0% â†’ 100%), while Sonnet 4.5 showed paradoxical worsening. A simple prompt-based intervention overall reduced socioeconomic bias and improved accuracy in LLM clinical recommendations, though effects varied across models. Prompt engineering may offer a practical approach to mitigating specific AI bias in healthcare.",
    "disease": "epilepsy",
    "clean_text": "is it possible to vaccinate ai against bias an exploratory study in epilepsy large language models are increasingly used for clinical decision support yet may perpetuate socioeconomic biases whether simple prompt based interventions can mitigate such biases remains unknown to determine whether a prompt based inoculation instructing large language models llms to disregard clinically irrelevant information can reduce bias and improve accuracy in recommendations experimental study conducted november to december each clinical vignette was presented times per condition to account for stochastic variance publicly available web interfaces of six frontier llms with memory features disabled no real patients were involved two fictional epilepsy vignettes diagnostic and therapeutic were created with identical clinical features but differing socioeconomic ses descriptors accuracy proportion of responses concordant with guidelines and bias accuracy difference between high and low ses vignettes assessed via binary scoring based on evidence based guidelines a total of llm responses were analyzed for diagnosis base accuracy was with percentage point bias gap high ses vs low ses inoculation improved accuracy to and reduced bias to percentage points for treatment base accuracy was with percentage point bias gap inoculation improved accuracy to and reduced bias to percentage points responses to inoculation varied considerably gemini pro showed complete diagnostic bias elimination low ses accuracy while sonnet showed paradoxical worsening a simple prompt based intervention overall reduced socioeconomic bias and improved accuracy in llm clinical recommendations though effects varied across models prompt engineering may offer a practical approach to mitigating specific ai bias in healthcare"
}