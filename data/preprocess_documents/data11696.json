{
    "pmid": "41471551",
    "title": "Deep Learning for Tumor Segmentation and Multiclass Classification in Breast Ultrasound Images Using Pretrained Models.",
    "abstract": "Early detection of breast cancer commonly relies on imaging technologies such as ultrasound, mammography and MRI. Among these, breast ultrasound is widely used by radiologists to identify and assess lesions. In this study, we developed image segmentation techniques and multiclass classification artificial intelligence (AI) tools based on pretrained models to segment lesions and detect breast cancer. The proposed workflow includes both the development of segmentation models and development of a series of classification models to classify ultrasound images as normal, benign or malignant. The pretrained models were trained and evaluated on the Breast Ultrasound Images (BUSI) dataset, a publicly available collection of grayscale breast ultrasound images with corresponding expert-annotated masks. For segmentation, images and ground-truth masks were used to pretrained encoder (ResNet18, EfficientNet-B0 and MobileNetV2)-decoder (U-Net, U-Net++ and DeepLabV3) models, including the DeepLabV3 architecture integrated with a Frequency-Domain Feature Enhancement Module (FEM). The proposed FEM improves spatial and spectral feature representations using Discrete Fourier Transform (DFT), GroupNorm, dropout regularization and adaptive fusion. For classification, each image was assigned a label (normal, benign or malignant). Optuna, an open-source software framework, was used for hyperparameter optimization and for the testing of various pretrained models to determine the best encoder-decoder segmentation architecture. Five different pretrained models (ResNet18, DenseNet121, InceptionV3, MobielNetV3 and GoogleNet) were optimized for multiclass classification. DeepLabV3 outperformed other segmentation architectures, with consistent performance across training, validation and test images, with Dice Similarity Coefficient (DSC, a metric describing the overlap between predicted and true lesion regions) values of 0.87, 0.80 and 0.83 on training, validation and test sets, respectively. ResNet18:DeepLabV3 achieved an Intersection over Union (IoU) score of 0.78 during training, while ResNet18:U-Net++ achieved the best Dice coefficient (0.83) and IoU (0.71) and area under the curve (AUC, 0.91) scores on the test (unseen) dataset when compared to other models. However, the proposed Resnet18: FrequencyAwareDeepLabV3 (FADeepLabV3) achieved a DSC of 0.85 and an IoU of 0.72 on the test dataset, demonstrating improvements over standard DeepLabV3. Notably, the frequency-domain enhancement substantially improved the AUC from 0.90 to 0.98, indicating enhanced prediction confidence and clinical reliability. For classification, ResNet18 produced an F1 score-a measure combining precision and recall-of 0.95 and an accuracy of 0.90 on the training dataset, while InceptionV3 performed best on the test dataset, with an F1 score of 0.75 and accuracy of 0.83. We demonstrate a comprehensive approach to automate the segmentation and multiclass classification of breast cancer ultrasound images into benign, malignant or normal transfer learning models on an imbalanced ultrasound image dataset.",
    "disease": "breast cancer",
    "clean_text": "deep learning for tumor segmentation and multiclass classification in breast ultrasound images using pretrained models early detection of breast cancer commonly relies on imaging technologies such as ultrasound mammography and mri among these breast ultrasound is widely used by radiologists to identify and assess lesions in this study we developed image segmentation techniques and multiclass classification artificial intelligence ai tools based on pretrained models to segment lesions and detect breast cancer the proposed workflow includes both the development of segmentation models and development of a series of classification models to classify ultrasound images as normal benign or malignant the pretrained models were trained and evaluated on the breast ultrasound images busi dataset a publicly available collection of grayscale breast ultrasound images with corresponding expert annotated masks for segmentation images and ground truth masks were used to pretrained encoder resnet efficientnet b and mobilenetv decoder u net u net and deeplabv models including the deeplabv architecture integrated with a frequency domain feature enhancement module fem the proposed fem improves spatial and spectral feature representations using discrete fourier transform dft groupnorm dropout regularization and adaptive fusion for classification each image was assigned a label normal benign or malignant optuna an open source software framework was used for hyperparameter optimization and for the testing of various pretrained models to determine the best encoder decoder segmentation architecture five different pretrained models resnet densenet inceptionv mobielnetv and googlenet were optimized for multiclass classification deeplabv outperformed other segmentation architectures with consistent performance across training validation and test images with dice similarity coefficient dsc a metric describing the overlap between predicted and true lesion regions values of and on training validation and test sets respectively resnet deeplabv achieved an intersection over union iou score of during training while resnet u net achieved the best dice coefficient and iou and area under the curve auc scores on the test unseen dataset when compared to other models however the proposed resnet frequencyawaredeeplabv fadeeplabv achieved a dsc of and an iou of on the test dataset demonstrating improvements over standard deeplabv notably the frequency domain enhancement substantially improved the auc from to indicating enhanced prediction confidence and clinical reliability for classification resnet produced an f score a measure combining precision and recall of and an accuracy of on the training dataset while inceptionv performed best on the test dataset with an f score of and accuracy of we demonstrate a comprehensive approach to automate the segmentation and multiclass classification of breast cancer ultrasound images into benign malignant or normal transfer learning models on an imbalanced ultrasound image dataset"
}